theme_bw() +
theme(text = element_text(family = "Arial"),
plot.title = element_text(face = "bold"),
axis.text.x = element_text(angle = 90, hjust = 1),
legend.position = "bottom",
axis.text = element_text(size = 9),
legend.title = element_blank()) +
labs(x = NULL, y = NULL,
title = "Sentiment analysis of Twitter statuses over time",
subtitle = "Tweets aggregated by hour on topics of #CoronaVirusSouthAfrica and #WhenCoronaVirusIsOver") +
scale_x_datetime(date_breaks = "24 hours", date_labels = "%b %d")
long_emotion_ts %>%
ggplot(aes(x = created_at, y = score, color=query)) +
geom_point() +
geom_smooth(method = "loess") +
facet_wrap(~ sentiment, scale = "free_y", nrow = 2) +
theme_bw() +
theme(text = element_text(family = "Arial"),
plot.title = element_text(face = "bold"),
axis.text.x = element_text(angle = 90, hjust = 1),
legend.position = "bottom",
axis.text = element_text(size = 9),
legend.title = element_blank()) +
labs(x = NULL, y = NULL,
title = "Sentiment analysis of Twitter statuses over time",
subtitle = "Tweets aggregated by hour on topics of #CoronaVirusSouthAfrica and #WhenCoronaVirusIsOver") +
scale_x_datetime(date_breaks = "24 hours", date_labels = "%b %d")
long_emotion_ts %>%
ggplot(aes(x = created_at, y = score, fill=query)) +
geom_point() +
geom_smooth(method = "loess") +
facet_wrap(~ sentiment, scale = "free_y", nrow = 2) +
theme_bw() +
theme(text = element_text(family = "Arial"),
plot.title = element_text(face = "bold"),
axis.text.x = element_text(angle = 90, hjust = 1),
legend.position = "bottom",
axis.text = element_text(size = 9),
legend.title = element_blank()) +
labs(x = NULL, y = NULL,
title = "Sentiment analysis of Twitter statuses over time",
subtitle = "Tweets aggregated by hour on topics of #CoronaVirusSouthAfrica and #WhenCoronaVirusIsOver") +
scale_x_datetime(date_breaks = "24 hours", date_labels = "%b %d")
long_emotion_ts$query
unique(long_emotion_ts$query)
long_emotion_ts
df %>%
## select variables (columns) of interest
dplyr::select(created_at, query, anger:positive)
cov_over$query <- "#WhenCoronaVirusIsOver"
covsa$query <- "#CoronaVirusSouthAfrica"
df <- rbind(covsa, covusa)
df
unique(df$query)
covsa
covsa$query <- "#CoronaVirusSouthAfrica"
covsa$query
unique(df$query)
df <- rbind(covsa, cov_over)
# ______________ Sentiment _____________
df$text_plain <- plain_tweets(df$text)
sa <- syuzhet::get_nrc_sentiment(df$text_plain)
df <- cbind(df, sa)
## create function for aggregating date-time vectors
round_time <- function(x, interval = 60) {
## round off to lowest value
rounded <- floor(as.numeric(x) / interval) * interval
## center so value is interval mid-point
rounded <- rounded + round(interval * .5, 0)
## return to date-time
as.POSIXct(rounded, origin = "1970-01-01")
}
## use pipe (%>%) operator for linear syntax
long_emotion_ts <- df %>%
## select variables (columns) of interest
dplyr::select(created_at, query, anger:positive) %>%
## convert created_at variable to desired interval
## here I chose 6 hour intervals (3 * 60 seconds * 60 mins = 3 hours)
mutate(created_at = round_time(created_at, 3 * 60 * 60)) %>%
## transform data to long form
tidyr::gather(sentiment, score, -created_at, -query) %>%
## group by time, query, and sentiment
group_by(created_at, query, sentiment) %>%
## get mean for each grouping
summarize(score = mean(score, na.rm = TRUE),
n = n()) %>%
ungroup()
long_emotion_ts
library(extrafont)
font_import()
loadfonts(device = "win")
long_emotion_ts %>%
ggplot(aes(x = created_at, y = score, fill=query)) +
geom_point() +
geom_smooth(method = "loess") +
facet_wrap(~ sentiment, scale = "free_y", nrow = 2) +
theme_bw() +
theme(text = element_text(family = "Arial"),
plot.title = element_text(face = "bold"),
axis.text.x = element_text(angle = 90, hjust = 1),
legend.position = "bottom",
axis.text = element_text(size = 9),
legend.title = element_blank()) +
labs(x = NULL, y = NULL,
title = "Sentiment analysis of Twitter statuses over time",
subtitle = "Tweets aggregated by hour on topics of #CoronaVirusSouthAfrica and #WhenCoronaVirusIsOver") +
scale_x_datetime(date_breaks = "24 hours", date_labels = "%b %d")
#________________________________
long_emotion_ts
long_emotion_ts[long_emotion_ts$query=='#WhenCoronaVirusIsOver',]
long_emotion_ts[long_emotion_ts$query=='#WhenCoronaVirusIsOver',]$score
long_emotion_ts[long_emotion_ts$query=='#WhenCoronaVirusIsOver',]$score <-
long_emotion_ts[long_emotion_ts$query=='#WhenCoronaVirusIsOver',]$score/2
long_emotion_ts %>%
ggplot(aes(x = created_at, y = score, fill=query)) +
geom_point() +
geom_smooth(method = "loess") +
facet_wrap(~ sentiment, scale = "free_y", nrow = 2) +
theme_bw() +
theme(text = element_text(family = "Arial"),
plot.title = element_text(face = "bold"),
axis.text.x = element_text(angle = 90, hjust = 1),
legend.position = "bottom",
axis.text = element_text(size = 9),
legend.title = element_blank()) +
labs(x = NULL, y = NULL,
title = "Sentiment analysis of Twitter statuses over time",
subtitle = "Tweets aggregated by hour on topics of #CoronaVirusSouthAfrica and #WhenCoronaVirusIsOver") +
scale_x_datetime(date_breaks = "24 hours", date_labels = "%b %d")
long_emotion_ts[long_emotion_ts$query=='#WhenCoronaVirusIsOver',]$score
long_emotion_ts[long_emotion_ts$query=='#WhenCoronaVirusIsOver',]$score/2
long_emotion_ts[long_emotion_ts$query=='#WhenCoronaVirusIsOver',]$score
long_emotion_ts[long_emotion_ts$query=='#WhenCoronaVirusIsOver',]$score =
long_emotion_ts[long_emotion_ts$query=='#WhenCoronaVirusIsOver',]$score/2
long_emotion_ts %>%
ggplot(aes(x = created_at, y = score, fill=query)) +
geom_point() +
geom_smooth(method = "loess") +
facet_wrap(~ sentiment, scale = "free_y", nrow = 2) +
theme_bw() +
theme(text = element_text(family = "Arial"),
plot.title = element_text(face = "bold"),
axis.text.x = element_text(angle = 90, hjust = 1),
legend.position = "bottom",
axis.text = element_text(size = 9),
legend.title = element_blank()) +
labs(x = NULL, y = NULL,
title = "Sentiment analysis of Twitter statuses over time",
subtitle = "Tweets aggregated by hour on topics of #CoronaVirusSouthAfrica and #WhenCoronaVirusIsOver") +
scale_x_datetime(date_breaks = "24 hours", date_labels = "%b %d")
gg <- ggplot(data=data_,aes(x=sentiment,y=sum_n)) +
geom_bar(aes(fill=sentiment),stat ="identity") +
xlab("Sentiments") + ylab("Scores") +
theme_minimal() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
ggtitle("Sentiment of #WhenCoronaVirusIsOver")
plot(gg)
hashtag = 'covid'
dataset <- search_tweets(hashtag, n=1000, include_rts = FALSE, token=token)
clean_ = clean_tweets_text(dataset, T)
data_ = diversified_sentiment_analysis(clean_, nrc_lexicon)
gg <- ggplot(data=data_,aes(x=sentiment,y=sum_n)) +
geom_bar(aes(fill=sentiment),stat ="identity") +
xlab("Sentiments") + ylab("Scores") +
theme_minimal() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
ggtitle("Sentiment of Covid Tweets")
plot(gg)
# net sentiment of tweets containing Covid
hashtag = 'Covid'
dataset <- search_tweets(hashtag, n=1000, include_rts = FALSE, token=token)
clean_ = clean_tweets_text(dataset, T)
data_ = diversified_sentiment_analysis(clean_, nrc_lexicon)
gg <- ggplot(data=data_,aes(x=sentiment,y=sum_n)) +
geom_bar(aes(fill=sentiment),stat ="identity") +
xlab("Sentiments") + ylab("Scores") +
theme_minimal() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
ggtitle("Sentiment of Covid Tweets")
plot(gg)
# ___________________________________ Install Dependencies & Curate Data ___________________________________
configure_workspace <- function() {
# Dependencies
# remotes::install_github("GuangchuangYu/nCov2019")
library(flexdashboard)
library(knitr)
library(shiny)
library(tidyverse)
library(coronavirus)
library(sf)
library(raster)
library(htmltab)
library(tmap)
library(leaflet)
library(ggplot2)
library(maptools)
library(rvest)
library(RColorBrewer)
library(htmlwidgets)
library(ggrepel)
library(nCov2019)
library(chinamap)
library(plotly)
library(tidyr)
library(ggrepel)
library(rgdal)
library(sp)
library(ggspatial)
library(rsconnect)
library(readxl)
# setwd("~/Desktop/covid19")
}
get_data <- function() {
# run to fetch & clean all the data
# ______________________________ South African Data ______________________________
# provincial data
province <- c('Western Cape','Eastern Cape','Northern Cape', 'Free State', 'KwaZulu-Natal', 'North West',
'Gauteng', 'Mpumalanga', 'Limpopo')
population <- c(6621103, 6522734, 1225555, 2954348, 11384722, 3978955, 14717040, 4523874, 5797275)
population_2 <- paste(round(population/1000000, 2), 'm', sep='')
density <- c(51.1, 38.6, 3.3, 22.8, 120.7, 37.9, 809.6, 59.1, 46.1)
provincial.data <- data.frame(province, population, population_2, density, stringsAsFactors=FALSE)
# --- Add later ---               # Gender & Age demographics
Age <- c('0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80+')
Male <- c('5 292 766','4 842 847','5 237 328','3 754 553','2 598 068','1 823 299','1 013 912','458 781','176 237')
Female <- c('5 212 437', '4 755 516', '5 196 531', '2 751 224', '2 970 834', '2 192 398', '1 329 660', '770 816', '402 352')
total <- c('10 505 203','9 598 363','10 433 859','6 505 777','5 568 902','4 015 697','2 343 572','1 229 597','419 989' )
age.data <- data.frame(Age, Male, Female,total, stringsAsFactors=FALSE)
# --- Add later ---
# Get South African Covid Data
covid_sa_url <- 'https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_South_Africa'
covid_sa <<- read_html(covid_sa_url) %>% html_node(xpath='//*[@id="mw-content-text"]/div/table[3]') %>% html_table(fill=T)
# geospatial data
#south_africa <<- readShapeSpatial('data/gadm36_ZAF_shp/gadm36_ZAF_1.shp')
# south_africa <<- rgdal::readOGR('data/sa_map_data/SOU-level_1.shp') #rgdal::readOGR('data/gadm36_ZAF_shp/gadm36_ZAF_1.shp')
# south_africa <- rgdal::readOGR('data/sa_map//gadm36_ZAF_1.shp')
# ______________________________ South African Data ______________________________
#  south_africa <<- rgdal::readOGR('data/sa_map/gadm36_ZAF_1.shp')
# _________________________________ Concatenate Data _________________________________
# Extract number of cases
test <- t(covid_sa[covid_sa$Day=='Cases',3:11])
test <- data.frame(test[1:nrow(test),])
colnames(test) <- 'Cases'
test$Cases <- as.numeric(as.character(test$Cases))
sa_cases <<- test
# add to dataframe
#south_africa@data <- cbind(test, south_africa@data)
# province data
#  south_africa@data <<- merge(south_africa@data, provincial.data, by.x='NAME_1', by.y='province')
# _________________________________ Concatenate Data _________________________________
# _________________________________ Global Data _________________________________
# global case data
n_cases <<- load_nCov2019(lang='en')
# median population data
med_age <<- read.csv('data/median-age.csv')
# clean
med_age <<- group_by(med_age, Entity) %>% filter(Year==2020) %>%
transmute(name=factor(Entity),
code=Code,
country=Entity,
median_age=UN.Population.Division..Median.Age...2017...years.)
# Global Population Data
global_population <<- read.csv('./data/global_population.csv')
# _________________________________ Global Data _________________________________
# _________________________________ Worldometer Data _________________________________
# Script to scrape summary data from 'https://www.worldometers.info/coronavirus/' and remove commas.
worldometer_url <- 'https://www.worldometers.info/coronavirus/'
worldometer <<- read_html(worldometer_url) %>% html_node(xpath='//*[@id="main_table_countries_today"]') %>% html_table(fill=T)
worldometer$TotalCases <- as.numeric(gsub(",","",worldometer$TotalCases))
worldometer$NewCases <- as.numeric(gsub(",","",worldometer$NewCases))
worldometer$TotalDeaths <- as.numeric(gsub(",","",worldometer$TotalDeaths))
worldometer$TotalCases <- as.numeric(gsub(",","",worldometer$TotalCases))
worldometer$NewDeaths <- as.numeric(gsub(",","",worldometer$NewDeaths))
worldometer$NewCases <- as.numeric(gsub(",","",worldometer$NewCases))
worldometer$TotalRecovered <- as.numeric(gsub(",","",worldometer$TotalRecovered))
worldometer$ActiveCases <- as.numeric(gsub(",","",worldometer$ActiveCases))
worldometer$`Serious,Critical` <- as.numeric(gsub(",","",worldometer$`Serious,Critical`))
worldometer$`Tot Cases/1M pop` <<- as.numeric(gsub(",","",worldometer$`Tot Cases/1M pop`))
# _________________________________ Worldometer Data _________________________________
#_____________________________ Scrape financial data ______________________________________
sp500_url <- 'https://za.investing.com/indices/us-spx-500-futures-historical-data'
sp500 <<- read_html(sp500_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
sa40_url <- 'https://za.investing.com/indices/south-africa-40-futures-historical-data'
sa40 <<- read_html(sa40_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
nasdaq_url <- 'https://za.investing.com/indices/nq-100-futures-historical-data'
nasdaq <<- read_html(nasdaq_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
london_url <- 'https://za.investing.com/equities/london-stock-exchange-historical-data'
london <<- read_html(london_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
nyse_url <- 'https://za.investing.com/indices/nyse-composite-historical-data'
nyse <<- read_html(nyse_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
ftse_url <- 'https://za.investing.com/indices/uk-100-historical-data'
ftse <<- read_html(ftse_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
hk50_url <- 'https://za.investing.com/indices/hang-sen-40-historical-data'
hk50 <<- read_html(hk50_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
gold_url <- 'https://za.investing.com/commodities/gold-historical-data'
gold <<- read_html(gold_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
zar_url <- 'https://za.investing.com/currencies/usd-zar-historical-data'
zar <<- read_html(zar_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[1]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
btc_url <- 'https://za.investing.com/crypto/bitcoin/btc-usd-historical-data'
btc <<- read_html(btc_url) %>% html_node(xpath= '//*[@id="curr_table"]') %>% html_table(fill = T)
#_____________________________ Scrape financial data ______________________________________
# _________________________________ World Map Data _________________________________
data("World")
# clean case data
case_data <- n_cases$global %>% group_by(country) %>%
summarise(cases=max(cum_confirm),
cum_heal=max(cum_heal),
cum_dead=max(cum_dead)) %>%
mutate(name=factor(country))
world <<- merge(World, case_data, by='name')                           # merge case data
world <<- merge(world, med_age, by='name')                             # merge median age data
world <<- merge(world, global_population, by='name', all.x=TRUE)       # add global population data
worldometer$name = worldometer$`Country,Other`
world2 <<- merge(world, worldometer, by='name')
}
active_ratio_donut_graph <- function(worldometer, country_) {
# Circular Graphic: Case Distribution
x <- filter(worldometer, `Country,Other`==country_)                        # filter data
data <- data.frame(country=country_,                                       # Create data
category=c("Active", "Deaths", "Recovered"),
count=c(as.numeric(sub(',', '',x$ActiveCases)),
as.numeric(sub(',', '',x$TotalDeaths)),
as.numeric(sub(',', '',x$TotalRecovered))))
data$fraction <- data$count / sum(data$count)                             # Compute percentages
data$ymax <- cumsum(data$fraction)                                        # Compute the cumulative percentages (top of each rectangle)
data$ymin <- c(0, head(data$ymax, n=-1))                                  # Compute the bottom of each rectangle
data$labelPosition <- (data$ymax + data$ymin) / 2                         # Compute label position
data$label <- paste0(data$category, "\n", data$count)                     # Compute a good label
# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
geom_rect() +
geom_text_repel(x=1, aes(y=labelPosition, label=label, color=category), size=6) +
# geom_text() + # x here controls label position (inner / outer)
scale_fill_brewer(palette=3) +
scale_color_brewer(palette=3) +
coord_polar(theta="y") +
xlim(c(-1, 4)) +
theme_void() +
theme(legend.position = "none") +
labs(title = paste("Covid-19", data$country, "Summary")) +
theme(plot.title = element_text(hjust = 0.5, size = 18, colour = 'darkgrey'))
}
colour_cases <- '#1f77b4'
colour_active <- 'lightblue'
colour_recovered <- 'darkgreen'
colour_dead <- 'darkred'
tmap_leaflet(
tm_shape(south_africa) +
tm_layout(title='Confirmed Cases in SA') +
tm_borders(alpha=0.3) +
tm_fill('Cases', title='Confirmed Cases', palette=c(RColorBrewer::brewer.pal(10, 'OrRd')[2:7]),
breaks=c(0,10,20,50,100,200),
popup.vars=c('cases'="Cases", "population_2", 'pop density'="density")))
tm_shape(south_africa) +
tm_layout(title='Confirmed Cases in SA') +
tm_borders(alpha=0.3) +
tm_fill('Cases', title='Confirmed Cases', palette=c(RColorBrewer::brewer.pal(10, 'OrRd')[2:7]),
breaks=c(0,10,20,50,100,200),
popup.vars=c('cases'="Cases", "population_2", 'pop density'="density"))
south_africa
}
get_data()
configure_workspace()
get_data()
# __________________________
tm_shape(south_africa) +
tm_layout(title='Confirmed Cases in SA') +
tm_borders(alpha=0.3) +
tm_fill('Cases', title='Confirmed Cases', palette=c(RColorBrewer::brewer.pal(10, 'OrRd')[2:7]),
breaks=c(0,10,20,50,100,200),
popup.vars=c('cases'="Cases", "population_2", 'pop density'="density"))
south_africa
setwd("~/Desktop/covid19")
setwd("~/Desktop/covid19")
getwd()
setwd("~/Desktop/SmarterThanCovid")
rgdal::readOGR('data/sa_map/gadm36_ZAF_1.shp')
get_data <- function() {
# run to fetch & clean all the data
# ______________________________ South African Data ______________________________
# provincial data
province <- c('Western Cape','Eastern Cape','Northern Cape', 'Free State', 'KwaZulu-Natal', 'North West',
'Gauteng', 'Mpumalanga', 'Limpopo')
population <- c(6621103, 6522734, 1225555, 2954348, 11384722, 3978955, 14717040, 4523874, 5797275)
population_2 <- paste(round(population/1000000, 2), 'm', sep='')
density <- c(51.1, 38.6, 3.3, 22.8, 120.7, 37.9, 809.6, 59.1, 46.1)
provincial.data <- data.frame(province, population, population_2, density, stringsAsFactors=FALSE)
# --- Add later ---               # Gender & Age demographics
Age <- c('0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80+')
Male <- c('5 292 766','4 842 847','5 237 328','3 754 553','2 598 068','1 823 299','1 013 912','458 781','176 237')
Female <- c('5 212 437', '4 755 516', '5 196 531', '2 751 224', '2 970 834', '2 192 398', '1 329 660', '770 816', '402 352')
total <- c('10 505 203','9 598 363','10 433 859','6 505 777','5 568 902','4 015 697','2 343 572','1 229 597','419 989' )
age.data <- data.frame(Age, Male, Female,total, stringsAsFactors=FALSE)
# --- Add later ---
# Get South African Covid Data
covid_sa_url <- 'https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_South_Africa'
covid_sa <<- read_html(covid_sa_url) %>% html_node(xpath='//*[@id="mw-content-text"]/div/table[3]') %>% html_table(fill=T)
# geospatial data
#south_africa <<- readShapeSpatial('data/gadm36_ZAF_shp/gadm36_ZAF_1.shp')
# south_africa <<- rgdal::readOGR('data/sa_map_data/SOU-level_1.shp') #rgdal::readOGR('data/gadm36_ZAF_shp/gadm36_ZAF_1.shp')
# south_africa <- rgdal::readOGR('data/sa_map//gadm36_ZAF_1.shp')
# ______________________________ South African Data ______________________________
south_africa <<- rgdal::readOGR('data/sa_map/gadm36_ZAF_1.shp')
# _________________________________ Concatenate Data _________________________________
# Extract number of cases
test <- t(covid_sa[covid_sa$Day=='Cases',3:11])
test <- data.frame(test[1:nrow(test),])
colnames(test) <- 'Cases'
test$Cases <- as.numeric(as.character(test$Cases))
sa_cases <<- test
# add to dataframe
south_africa@data <- cbind(test, south_africa@data)
# province data
south_africa@data <<- merge(south_africa@data, provincial.data, by.x='NAME_1', by.y='province')
# _________________________________ Concatenate Data _________________________________
# _________________________________ Global Data _________________________________
# global case data
n_cases <<- load_nCov2019(lang='en')
# median population data
med_age <<- read.csv('data/median-age.csv')
# clean
med_age <<- group_by(med_age, Entity) %>% filter(Year==2020) %>%
transmute(name=factor(Entity),
code=Code,
country=Entity,
median_age=UN.Population.Division..Median.Age...2017...years.)
# Global Population Data
global_population <<- read.csv('./data/global_population.csv')
# _________________________________ Global Data _________________________________
# _________________________________ Worldometer Data _________________________________
# Script to scrape summary data from 'https://www.worldometers.info/coronavirus/' and remove commas.
worldometer_url <- 'https://www.worldometers.info/coronavirus/'
worldometer <<- read_html(worldometer_url) %>% html_node(xpath='//*[@id="main_table_countries_today"]') %>% html_table(fill=T)
worldometer$TotalCases <- as.numeric(gsub(",","",worldometer$TotalCases))
worldometer$NewCases <- as.numeric(gsub(",","",worldometer$NewCases))
worldometer$TotalDeaths <- as.numeric(gsub(",","",worldometer$TotalDeaths))
worldometer$TotalCases <- as.numeric(gsub(",","",worldometer$TotalCases))
worldometer$NewDeaths <- as.numeric(gsub(",","",worldometer$NewDeaths))
worldometer$NewCases <- as.numeric(gsub(",","",worldometer$NewCases))
worldometer$TotalRecovered <- as.numeric(gsub(",","",worldometer$TotalRecovered))
worldometer$ActiveCases <- as.numeric(gsub(",","",worldometer$ActiveCases))
worldometer$`Serious,Critical` <- as.numeric(gsub(",","",worldometer$`Serious,Critical`))
worldometer$`Tot Cases/1M pop` <<- as.numeric(gsub(",","",worldometer$`Tot Cases/1M pop`))
# _________________________________ Worldometer Data _________________________________
#_____________________________ Scrape financial data ______________________________________
sp500_url <- 'https://za.investing.com/indices/us-spx-500-futures-historical-data'
sp500 <<- read_html(sp500_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
sa40_url <- 'https://za.investing.com/indices/south-africa-40-futures-historical-data'
sa40 <<- read_html(sa40_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
nasdaq_url <- 'https://za.investing.com/indices/nq-100-futures-historical-data'
nasdaq <<- read_html(nasdaq_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
london_url <- 'https://za.investing.com/equities/london-stock-exchange-historical-data'
london <<- read_html(london_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
nyse_url <- 'https://za.investing.com/indices/nyse-composite-historical-data'
nyse <<- read_html(nyse_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
ftse_url <- 'https://za.investing.com/indices/uk-100-historical-data'
ftse <<- read_html(ftse_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
hk50_url <- 'https://za.investing.com/indices/hang-sen-40-historical-data'
hk50 <<- read_html(hk50_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
gold_url <- 'https://za.investing.com/commodities/gold-historical-data'
gold <<- read_html(gold_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[2]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
zar_url <- 'https://za.investing.com/currencies/usd-zar-historical-data'
zar <<- read_html(zar_url) %>% html_node(xpath='//*[@id="js-main-container"]/section[1]/div/section[2]/section[2]/div[1]/div/table') %>% html_table(fill = T)
btc_url <- 'https://za.investing.com/crypto/bitcoin/btc-usd-historical-data'
btc <<- read_html(btc_url) %>% html_node(xpath= '//*[@id="curr_table"]') %>% html_table(fill = T)
#_____________________________ Scrape financial data ______________________________________
# _________________________________ World Map Data _________________________________
data("World")
# clean case data
case_data <- n_cases$global %>% group_by(country) %>%
summarise(cases=max(cum_confirm),
cum_heal=max(cum_heal),
cum_dead=max(cum_dead)) %>%
mutate(name=factor(country))
world <<- merge(World, case_data, by='name')                           # merge case data
world <<- merge(world, med_age, by='name')                             # merge median age data
world <<- merge(world, global_population, by='name', all.x=TRUE)       # add global population data
worldometer$name = worldometer$`Country,Other`
world2 <<- merge(world, worldometer, by='name')
}
get_data()
tm_shape(south_africa) +
tm_layout(title='Confirmed Cases in SA') +
tm_borders(alpha=0.3) +
tm_fill('Cases', title='Confirmed Cases', palette=c(RColorBrewer::brewer.pal(10, 'OrRd')[2:7]),
breaks=c(0,10,20,50,100,200),
popup.vars=c('cases'="Cases", "population_2", 'pop density'="density"))
south_africa
tm_shape(south_africa) +
tm_layout(title='Confirmed Cases in SA') +
tm_borders(alpha=0.3) +
tm_fill('Cases', title='Confirmed Cases', palette=c(RColorBrewer::brewer.pal(9, 'OrRd')[2:7]),
breaks=c(0,10,20,50,100,200),
popup.vars=c('cases'="Cases", "population_2", 'pop density'="density"))
tmap <- tm_shape(south_africa) +
tm_layout(title='Confirmed Cases in SA') +
tm_borders(alpha=0.3) +
tm_fill('Cases', title='Confirmed Cases', palette=c(RColorBrewer::brewer.pal(9, 'OrRd')[2:7]),
breaks=c(0,10,20,50,100,200),
popup.vars=c('cases'="Cases", "population_2", 'pop density'="density"))
tmap
tmap_mode('view')
tm_shape(south_africa) +
tm_layout(title='Confirmed Cases in SA') +
tm_borders(alpha=0.3) +
tm_fill('Cases', title='Confirmed Cases', palette=c(RColorBrewer::brewer.pal(9, 'OrRd')[2:7]),
breaks=c(0,10,20,50,100,200),
popup.vars=c('cases'="Cases", "population_2", 'pop density'="density"))
plot(tmap)
